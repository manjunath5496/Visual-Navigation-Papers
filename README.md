<p><strong>Visual Navigation</strong> is the problem of navigating an agent, e.g. a mobile robot, in an environment using camera input only. The agent is given a target image (an image it will see from the target position), and its goal is to move from its current position to the target by applying a sequence of actions, based on the camera observations only.</p>
</br>

<h2> Papers </h2> 

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(1).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(2).pdf" style="text-decoration:none;">A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(3).pdf" style="text-decoration:none;">Visual Representations for Semantic Target Driven Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(4).pdf" style="text-decoration:none;">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(5).pdf" style="text-decoration:none;">Learning to Learn How to Learn:
Self-Adaptive Visual Navigation using Meta-Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(6).pdf" style="text-decoration:none;">Self-Monitoring Navigation Agent via Auxiliary Progress Estimation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(7).pdf" style="text-decoration:none;">The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(8).pdf" style="text-decoration:none;">The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(9).pdf" style="text-decoration:none;">Scaling and Benchmarking Self-Supervised Visual Representation Learning</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(10).pdf" style="text-decoration:none;">An Open Source and Open Hardware
Deep Learning-powered Visual Navigation Engine for Autonomous Nano-UAVs</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(11).pdf" style="text-decoration:none;">SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(12).pdf" style="text-decoration:none;">Vision-and-Dialog Navigation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(13).pdf" style="text-decoration:none;">Help, Anna! Visual Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(14).pdf" style="text-decoration:none;">CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(15).pdf" style="text-decoration:none;">A Hybrid Compact Neural Architecture for Visual Place Recognition</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(16).pdf" style="text-decoration:none;">Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(17).pdf" style="text-decoration:none;">Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(18).pdf" style="text-decoration:none;">Discriminative Particle Filter Reinforcement Learning for Complex Partial Observations</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(19).pdf" style="text-decoration:none;">Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-training</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(20).pdf" style="text-decoration:none;">MVP: Unified Motion and Visual Self-Supervised Learning for Large-Scale Robotic Navigation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(21).pdf" style="text-decoration:none;">Extending Maps with Semantic and Contextual Object Information for Robot Navigation: a Learning-Based Framework using Visual and Depth Cues</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(22).pdf" style="text-decoration:none;">Sparse Graphical Memory for Robust Planning</a></li> 
 
 
 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(23).pdf" style="text-decoration:none;">Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(24).pdf" style="text-decoration:none;">Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(25).pdf" style="text-decoration:none;">Cognitive Mapping and Planning for Visual Navigation</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(26).pdf" style="text-decoration:none;">VUSFA: Variational Universal Successor Features Approximator to Improve Transfer DRL for Target Driven Visual Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(27).pdf" style="text-decoration:none;">Visual Navigation Among Humans with Optimal Control as a Supervisor</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(28).pdf" style="text-decoration:none;">One-Shot Informed Robotic Visual Search in the Wild</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Visual-Navigation-Papers/blob/master/vnn(29).pdf" style="text-decoration:none;">Learning Object Relation Graph and Tentative Policy for Visual Navigation</a></li>                              

</ul>
